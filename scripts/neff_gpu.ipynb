{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from af22c.proteome import MultipleSeqAlign\n",
    "import matplotlib.pyplot as plt\n",
    "from timeit import timeit\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations, chain\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prot_path = \"../data/A0A0A0MRZ7.a3m\"\n",
    "prot = MultipleSeqAlign.from_a3m(prot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab = sorted(list(set(\"\".join([str(prot.query_seq)] + [str(match.aligned_seq) for match in prot.matches]))))\n",
    "\"\".join(vocab),len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stoi = {c:i for i, c in enumerate(vocab)}\n",
    "itos = {i:c for c, i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_len = len(prot.query_seq)\n",
    "num_matches = len(prot.matches)\n",
    "num_seqs = num_matches + 1 # include query\n",
    "query_len,num_matches,num_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encmsa = torch.zeros((num_seqs, query_len))\n",
    "for seqidx, seq in enumerate([prot.query_seq] + [match.aligned_seq for match in prot.matches]):\n",
    "    for colidx, colval in enumerate(seq):\n",
    "        encmsa[seqidx, colidx] = stoi[colval]\n",
    "encmsa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(encmsa[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "smallmsa = encmsa[:10,8:18] # (num_seqs, query_len)\n",
    "# adjust variables for toy example\n",
    "num_seqs, query_len = smallmsa.shape\n",
    "num_matches = num_seqs - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(smallmsa)\n",
    "plt.ylabel(\"match\")\n",
    "plt.xlabel(\"AA index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pairwise hamming distances\n",
    "pwdists = torch.sum(smallmsa[None,:,:] != smallmsa[:,None,:], axis=-1)\n",
    "# pairwise sequence identities = 1 - normalized hamming distances (each value divided by sequence length)\n",
    "pwseq = 1 - pwdists / query_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(pwseq)\n",
    "plt.xlabel(\"target seq idx\")\n",
    "plt.ylabel(\"query seq idx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pwseq[0,0],pwseq[0,3],pwseq[0,4],pwseq[0,7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "with our MSA sizes, it is probably not feasible to run sequence identity checks on the entire MSA. therefore, we need to divide the MSA into smaller batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 4 # number of sequenes in batch\n",
    "# calculate all pairs for which pairwise sequence identities need to be calculated\n",
    "#pairs = torch.cartesian_prod(*(torch.arange(num_seqs),)*2)\n",
    "pairs = []\n",
    "for i in range(num_seqs):\n",
    "    for j in range(i+1, num_seqs):\n",
    "        pairs.append((i,j))\n",
    "pairs = torch.tensor(pairs)\n",
    "pairs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# each batch should yield a matrix with batch_size elements\n",
    "num_batches = (len(pairs) + batch_size - 1) // batch_size\n",
    "num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# one batch contains batch_size many pairs, which yields batch_size many similarity scores because the \n",
    "# similarity matrix is symmetric.\n",
    "bpwseq = torch.eye(num_seqs) # matrix containing similarity scores for two sequences\n",
    "for batch_idx in range(num_batches):\n",
    "    # calculate similarity scores for a batch\n",
    "    pairs_idx = torch.arange(batch_idx*batch_size, min((batch_idx + 1)*batch_size, len(pairs)))\n",
    "    batch_pairs = pairs[pairs_idx]\n",
    "\n",
    "    # calculate sequences in batch\n",
    "    batch_seqs = torch.zeros((batch_size, 2, query_len))\n",
    "    for pair_idx, (i, j) in enumerate(batch_pairs):\n",
    "        # TODO: get rid of float conversion?\n",
    "        batch_seqs[pair_idx, 0] = smallmsa[i].float()\n",
    "        batch_seqs[pair_idx, 1] = smallmsa[j].float()\n",
    "\n",
    "    batch_pwdists = torch.sum(batch_seqs[:,0,:] != batch_seqs[:,1,:], axis=-1)\n",
    "    batch_pwseq = 1 - batch_pwdists / query_len\n",
    "    for pair_idx, (i, j) in enumerate(batch_pairs):\n",
    "        bpwseq[i,j] = bpwseq[j,i] = batch_pwseq[pair_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig,(ax1,ax2) = plt.subplots(ncols=2)\n",
    "ax1.imshow(bpwseq)\n",
    "ax1.set_title(\"batch pairwise seq identity\")\n",
    "ax2.imshow(pwseq)\n",
    "ax2.set_title(\"complete MSA pairwise seq identity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(bpwseq, pwseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# baseline: 30.474739761004457s\n",
    "timeit(lambda: prot.compute_neff(), number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from neff_gpu import neff\n",
    "neff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#timeit(lambda: compute_neff(prot), number=1)\n",
    "# baseline: 20.309782647993416s\n",
    "timeit(lambda: neff(prot, batch_size=10000), number=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined functionality\n",
    "\n",
    "The cells below combine the derived Neff score calculations from the cells above to be able to evaluate small changes to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fn1(encmsa):\n",
    "    batch_size = 4 # number of sequenes in batch\n",
    "    # calculate all pairs for which pairwise sequence identities need to be calculated\n",
    "    #pairs = torch.cartesian_prod(*(torch.arange(num_seqs),)*2)\n",
    "    pairs = []\n",
    "    for i in range(num_seqs):\n",
    "        for j in range(i+1, num_seqs):\n",
    "            pairs.append((i,j))\n",
    "    pairs = torch.tensor(pairs)\n",
    "    \n",
    "    # each batch should yield a matrix with batch_size elements\n",
    "    num_batches = (len(pairs) + batch_size - 1) // batch_size\n",
    "    \n",
    "    bpwseq = torch.eye(num_seqs) # matrix containing similarity scores for two sequences\n",
    "    for batch_idx in range(num_batches):\n",
    "        # calculate similarity scores for a batch\n",
    "        pairs_idx = torch.arange(batch_idx*batch_size, min((batch_idx + 1)*batch_size, len(pairs)))\n",
    "        batch_pairs = pairs[pairs_idx]\n",
    "\n",
    "        # calculate sequences in batch\n",
    "        batch_seqs = torch.zeros((batch_size, 2, query_len))\n",
    "        for pair_idx, (i, j) in enumerate(batch_pairs):\n",
    "            # TODO: get rid of float conversion?\n",
    "            batch_seqs[pair_idx, 0] = encmsa[i].float()\n",
    "            batch_seqs[pair_idx, 1] = encmsa[j].float()\n",
    "\n",
    "        batch_pwdists = torch.sum(batch_seqs[:,0,:] != batch_seqs[:,1,:], axis=-1)\n",
    "        batch_pwseq = 1 - batch_pwdists / query_len\n",
    "        for pair_idx, (i, j) in enumerate(batch_pairs):\n",
    "            bpwseq[i,j] = bpwseq[j,i] = batch_pwseq[pair_idx]\n",
    "    return bpwseq\n",
    "assert torch.allclose(fn1(smallmsa), pwseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fn2(encmsa):\n",
    "    batch_size = 4 # number of sequenes in batch\n",
    "    # calculate all pairs for which pairwise sequence identities need to be calculated\n",
    "    #pairs = torch.cartesian_prod(*(torch.arange(num_seqs),)*2)\n",
    "    pairs = []\n",
    "    for i in range(num_seqs):\n",
    "        for j in range(i+1, num_seqs):\n",
    "            pairs.append((i,j))\n",
    "    pairs = torch.tensor(pairs)\n",
    "    \n",
    "    # each batch should yield a matrix with batch_size elements\n",
    "    num_batches = (len(pairs) + batch_size - 1) // batch_size\n",
    "    \n",
    "    bpwseq = torch.eye(num_seqs) # matrix containing similarity scores for two sequences\n",
    "    for batch_idx in range(num_batches):\n",
    "        # calculate similarity scores for a batch\n",
    "        pairs_idx = torch.arange(batch_idx*batch_size, min((batch_idx + 1)*batch_size, len(pairs)))\n",
    "        batch_pairs = pairs[pairs_idx]\n",
    "        batch_pairs_flat = batch_pairs.view(-1)\n",
    "        \n",
    "        # calculate sequences in batch\n",
    "        batch_seqs = encmsa[batch_pairs_flat]\n",
    "        batch_seqs = batch_seqs.view((-1, 2, query_len))\n",
    "\n",
    "        # calculate pairwise distances \n",
    "        batch_pwdists = torch.sum(batch_seqs[:,0,:] != batch_seqs[:,1,:], axis=-1)\n",
    "        batch_pwseq = 1 - batch_pwdists / query_len\n",
    "        \n",
    "        # put at right location in result matrix\n",
    "        bpwseq[batch_pairs[:,0],batch_pairs[:,1]] = batch_pwseq\n",
    "        bpwseq[batch_pairs[:,1],batch_pairs[:,0]] = batch_pwseq\n",
    "    return bpwseq\n",
    "assert torch.allclose(fn2(smallmsa), pwseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"fn1: {timeit(lambda: fn1(smallmsa), number=100)}s\")\n",
    "print(f\"fn2: {timeit(lambda: fn2(smallmsa), number=100)}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fn3(encmsa, device=None, batch_size = 4096, **kwargs):\n",
    "    num_seqs,query_len = encmsa.shape\n",
    "\n",
    "    # calculate all pairs for which pairwise sequence identities need to be calculated\n",
    "    pairs = torch.triu_indices(*(num_seqs,)*2, 1, device=device).T\n",
    "    \n",
    "    # each batch should yield a matrix with batch_size elements\n",
    "    num_batches = (len(pairs) + batch_size - 1) // batch_size\n",
    "    \n",
    "    bpwseq = torch.eye(num_seqs, device=device) # matrix containing similarity scores for two sequences\n",
    "    for batch_idx in tqdm(range(num_batches), desc=\"running batches\"):\n",
    "        # calculate similarity scores for a batch\n",
    "        pairs_idx = torch.arange(batch_idx*batch_size, min((batch_idx + 1)*batch_size, len(pairs)))\n",
    "        batch_pairs = pairs[pairs_idx]\n",
    "        batch_pairs_flat = batch_pairs.view(-1)\n",
    "        \n",
    "        # calculate sequences in batch\n",
    "        batch_seqs = encmsa[batch_pairs_flat]\n",
    "        batch_seqs = batch_seqs.view((-1, 2, query_len))\n",
    "\n",
    "        # calculate pairwise distances \n",
    "        batch_pwdists = torch.sum(batch_seqs[:,0,:] != batch_seqs[:,1,:], axis=-1)\n",
    "        batch_pwseq = 1 - batch_pwdists / query_len\n",
    "        \n",
    "        # put at right location in result matrix\n",
    "        bpwseq[batch_pairs[:,0],batch_pairs[:,1]] = batch_pwseq\n",
    "        bpwseq[batch_pairs[:,1],batch_pairs[:,0]] = batch_pwseq\n",
    "    return bpwseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gapcount(encmsa, weights=None, gaptok=None, stoi=None, nongap=False, **kwargs):\n",
    "    \"\"\"\n",
    "    calculate number of gaps in each msa column. returns a vector of length query_len.\n",
    "    weights can be specified to weight each sequence in the msa column.\n",
    "    if nongap=False (default), gaps will be counted; otherwise non-gaps will be counted.\n",
    "    the gaps are identified by gaptok, which can be the token id for gaps. alternatively, a\n",
    "    dictionary stoi can be supplied, where the gaptok is looked up.\n",
    "    \"\"\"\n",
    "    if gaptok is None:\n",
    "        assert stoi is not None\n",
    "        gaptok = stoi['-']\n",
    "    gapindicator = encmsa != gaptok if nongap else encmsa == gaptok\n",
    "    if weights is not None:\n",
    "        return weights @ gapindicator.float()\n",
    "    return torch.sum(gapindicator, dim=0)\n",
    "\n",
    "def neff(encmsa, pwseqfn=fn3, seqid_thres=0.8, **kwargs):\n",
    "    \"\"\"\n",
    "    calculate neff scores for an encoded msa.\n",
    "    \"\"\"\n",
    "    num_seqs, query_len = encmsa.shape\n",
    "    pwseq = pwseqfn(encmsa, **kwargs)\n",
    "    # calculate neff weights (dim can be 0 or 1, does not matter because pwseq is symmetric)\n",
    "    neffweights = 1 / torch.sum(pwseq >= seqid_thres, dim=0)\n",
    "    return gapcount(encmsa, weights=neffweights, nongap=True, **kwargs)\n",
    "\n",
    "#neff_fast = neff(encmsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accellerating file loading\n",
    "\n",
    "In the new neff score calculation, a lot of time is spent encoding the MSA. Can we combine file loading and encoding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "neffref = prot.compute_neff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from string import ascii_lowercase\n",
    "def loadmsa(path):\n",
    "    \"\"\"load an MSA as an encoded tensor\"\"\"\n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "        assert not len(lines) & 1, f\"MSA at {path} should contain an even number of lines\"\n",
    "        query_id = lines[0].split()[0]\n",
    "        query_len = len([() for ch in lines[1].strip() if not ch in ascii_lowercase])\n",
    "        \n",
    "        # count header lines that are not just the query ID (1+ because first query is included in encoded msa)\n",
    "        num_seqs = 1 + len([1 for line in lines[::2] if not line[:-1] == query_id and line.startswith(\">\")])\n",
    "        \n",
    "        # encode msa from lines\n",
    "        encmsa = torch.zeros((num_seqs,query_len), dtype=torch.uint8)\n",
    "        idx = 0\n",
    "        for hdr, seq in zip(lines[::2], lines[1::2]):\n",
    "            # skip query that appears multiple times in the file\n",
    "            if idx > 1 and hdr[:-1] == query_id:\n",
    "                continue\n",
    "            # encode sequence\n",
    "            encmsa[idx,:] = torch.tensor(\n",
    "                # NB: stoi comes from outside!\n",
    "                [stoi[ch] for ch in seq[:-1] if not ch in ascii_lowercase],\n",
    "                dtype=torch.uint8,\n",
    "            )\n",
    "            idx += 1\n",
    "        return encmsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loadedmsa=loadmsa(prot_path)\n",
    "loadedmsa.shape,len(prot.matches)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# avg 5.556711397999607s per run\n",
    "def f():\n",
    "    loadedmsa=loadmsa(prot_path)\n",
    "    return neff(loadedmsa, stoi=stoi)\n",
    "timeit(f,number=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nefffast = f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(torch.tensor(neffref).float() - nefffast)\n",
    "torch.allclose(torch.tensor(neffref).float(), nefffast) # yields true, are they \"equal enough\"? :3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(neffref)\n",
    "plt.plot(nefffast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline: 15.939979004993802s\n",
    "# with better pair generation: 4.461970445991028s\n",
    "timeit(lambda: neff(loadmsa(prot_path), stoi=stoi), number=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating pairs\n",
    "\n",
    "The second thing taking a long time is the generating a list of pairs that need to be processed. This can be done faster..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,m=100,100\n",
    "def combipairs(num_seqs):\n",
    "    return list(combinations(range(num_seqs),2))\n",
    "def triupairs(num_seqs):\n",
    "    return torch.triu_indices(*(num_seqs,)*2,1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit(lambda: combipairs(n), number=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit(lambda: triupairs(n), number=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combipairs(4),triupairs(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "encmsa = loadmsa(prot_path).to(device)\n",
    "neff(encmsa, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "num_seqs = 5\n",
    "\n",
    "pairs = torch.triu_indices(*(num_seqs,)*2,1).T\n",
    "num_full_batches = len(pairs) // batch_size\n",
    "batch_pairs = pairs[:-(len(pairs)%batch_size)]\n",
    "rest_pairs = pairs[-(len(pairs)%batch_size):]\n",
    "pairs.shape,batch_pairs.shape,rest_pairs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pairs,batch_pairs,rest_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ptr = lambda t: t.storage().data_ptr()\n",
    "ptr(pairs),ptr(batch_pairs),ptr(rest_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ptr(batch_pairs.view(num_full_batches, -1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for bp in chain(batch_pairs.view(num_full_batches, -1, 2), [rest_pairs]):\n",
    "    print(ptr(bp.view(-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare the performance of two versions of the pwseq function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# baseline\n",
    "def pwseq1(encmsa, device=None, batch_size=2**18, **kwargs):\n",
    "  \"\"\"return pairwise sequence identity calculated with pytorch\"\"\"\n",
    "  num_seqs,query_len = encmsa.shape\n",
    "  \n",
    "  # calculate all pairs for which pairwise sequence identities need to be calculated\n",
    "  pairs = torch.triu_indices(*(num_seqs,)*2, 1, device=device).T\n",
    "  \n",
    "  # each batch should yield a matrix with batch_size elements\n",
    "  num_batches = (len(pairs) + batch_size - 1) // batch_size\n",
    "  \n",
    "  # one batch contains batch_size many pairs, which yields batch_size many similarity scores because the \n",
    "  # similarity matrix is symmetric.\n",
    "  bpwseq = torch.eye(num_seqs, device=device) # matrix containing similarity scores for two sequences\n",
    "  for batch_idx in tqdm(range(num_batches), desc=\"running batches\"):\n",
    "    # calculate similarity scores for a batch\n",
    "    pairs_idx = torch.arange(batch_idx*batch_size, min((batch_idx + 1)*batch_size, len(pairs)))\n",
    "    batch_pairs = pairs[pairs_idx]\n",
    "    batch_pairs_flat = batch_pairs.view(-1)\n",
    "    \n",
    "    # calculate sequences in batch\n",
    "    batch_seqs = encmsa[batch_pairs_flat]\n",
    "    batch_seqs = batch_seqs.view(-1, 2, query_len)\n",
    "\n",
    "    # calculate pairwise distances \n",
    "    batch_pwdists = torch.sum(batch_seqs[:,0,:] != batch_seqs[:,1,:], axis=-1)\n",
    "    batch_pwseq = 1 - batch_pwdists / query_len\n",
    "    \n",
    "    # put at right location in result matrix (and make symmetric)\n",
    "    bpwseq[batch_pairs[:,0],batch_pairs[:,1]] = batch_pwseq\n",
    "    bpwseq[batch_pairs[:,1],batch_pairs[:,0]] = batch_pwseq\n",
    "  return bpwseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pwseq2(encmsa, device=None, batch_size=2**12, **kwargs):\n",
    "  \"\"\"return pairwise sequence identity calculated with pytorch\"\"\"\n",
    "  num_seqs,query_len = encmsa.shape\n",
    "  \n",
    "  # calculate all pairs for which pairwise sequence identities need to be calculated\n",
    "  pairs = torch.triu_indices(*(num_seqs,)*2, 1, device=device).T\n",
    "  \n",
    "  # each batch should yield a matrix with batch_size elements\n",
    "  num_batches = (len(pairs) + batch_size - 1) // batch_size\n",
    "  num_full_batches = len(pairs) // batch_size\n",
    "  \n",
    "  batch_pairs = pairs[:-(len(pairs)%batch_size)]\n",
    "  rest_pairs = pairs[-(len(pairs)%batch_size):]\n",
    "\n",
    "  checkpoints = \"seq_extract pwdists putback\"\n",
    "  t = {name: 0 for name in checkpoints.split()}\n",
    "  \n",
    "  # put pairs into batches\n",
    "  batches = batch_pairs.view(num_full_batches, -1, 2)\n",
    "  if num_batches != num_full_batches:\n",
    "    batches = chain(batches, [rest_pairs])\n",
    "    \n",
    "  # one batch contains batch_size many pairs, which yields batch_size many similarity scores because the \n",
    "  # similarity matrix is symmetric.\n",
    "  bpwseq = torch.eye(num_seqs, device=device) # matrix containing similarity scores for two sequences\n",
    "  for batch_pairs in tqdm(batches, total=num_batches, desc=\"running batches\"):\n",
    "    # view batch_pairs as a flat array\n",
    "    #start = time.perf_counter()\n",
    "    #print(f\"{batch_pairs.shape=}\")\n",
    "    #batch_pairs_flat = batch_pairs.view(-1)\n",
    "    #break\n",
    "    #end = time.perf_counter()\n",
    "    #t[\"pairflatten\"] += end - start\n",
    "    \n",
    "    # extract sequences in batch\n",
    "    start = time.perf_counter()\n",
    "    #batch_seqs = encmsa[batch_pairs_flat]\n",
    "    batch_seqs = encmsa[batch_pairs]\n",
    "    #batch_seqs = batch_seqs.view(-1, 2, query_len)\n",
    "    #print(f\"{batch_seqs.shape}\")\n",
    "    end = time.perf_counter()\n",
    "    t[\"seq_extract\"] += end - start\n",
    "\n",
    "    # calculate pairwise distances \n",
    "    start = time.perf_counter()\n",
    "    batch_pwdists = torch.sum(batch_seqs[:,0,:] != batch_seqs[:,1,:], axis=-1)\n",
    "    batch_pwseq = 1 - batch_pwdists / query_len\n",
    "    end = time.perf_counter()\n",
    "    t[\"pwdists\"] += end - start\n",
    "    \n",
    "    # put at right location in result matrix (and make symmetric)\n",
    "    start = time.perf_counter()\n",
    "    bpwseq[batch_pairs[:,0],batch_pairs[:,1]] = batch_pwseq\n",
    "    bpwseq[batch_pairs[:,1],batch_pairs[:,0]] = batch_pwseq\n",
    "    end = time.perf_counter()\n",
    "    t[\"putback\"] += end - start\n",
    "  \n",
    "  c = sum(t.values())\n",
    "  for name, total in t.items():\n",
    "    print(f\"{name}: {total}s={100*total/c:.01f}%, {total/num_batches}s/batch\")\n",
    "  print(f\"sum={c}\")\n",
    "  \n",
    "  return bpwseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pwseq2(encmsa, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encmsa = loadmsa(\"../data/A0A0A0MRZ7.a3m\")\n",
    "encmsa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size=2**12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"baseline\", timeit(lambda: pwseq1(encmsa, batch_size=batch_size), number=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"version 2\", timeit(lambda: pwseq2(encmsa, batch_size=batch_size), number=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
